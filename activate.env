ROOTDIR="$(dirname $0)"
ROOTDIR="$(realpath $ROOTDIR)"
echo "Hadoop/Spark/Scala Package Root Dir = $ROOTDIR"
PWD0="$(pwd)"

cd $ROOTDIR
SPARK_HOME="$(find . -maxdepth 1 -type d -name "spark*" | head -n 1)"
export SPARK_HOME="$(realpath $SPARK_HOME)"
echo "Spark Home = $SPARK_HOME"
SCALA_HOME="$(find . -maxdepth 1 -type d -name "scala*" | head -n 1)"
export SCALA_HOME="$(realpath $SCALA_HOME)"
echo "Scala Home = $SCALA_HOME"
HADOOP_HOME="$(find . -maxdepth 1 -type d -name "*hadoop*" | head -n 1)"
export HADOOP_HOME="$(realpath $HADOOP_HOME)"
echo "Hadoop Home = $HADOOP_HOME"
JAVA_HOME="$(find . -maxdepth 1 -type d -name "jdk*" | head -n 1)"
export JAVA_HOME="$(realpath $JAVA_HOME)"
echo "Java Home = $JAVA_HOME"

if [ -e "$SPARK_HOME/conf/spark-env.sh" ] ; then
	echo "Make sure that there is a sensible setting for SPARK_DIST_CLASSPATH including hadoop jars..."
	echo "...between here>>>"
	cat "$SPARK_HOME/conf/spark-env.sh" | grep 'export SPARK_DIST_CLASSPATH'
	echo "<<<and here."
else
	cp "$SPARK_HOME/conf/spark-env.sh.template" "$SPARK_HOME/conf/spark-env.sh"
	cat - >> "$SPARK_HOME/conf/spark-env.sh" <<EOF
export SPARK_DIST_CLASSPATH="$(hadoop classpath):\$SPARK_DIST_CLASSPATH"
EOF
fi

export PATH="$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$SPARK_HOME/bin:$SPARK_HOME/sbin:$JAVA_HOME/bin:$SCALA_HOME/bin:$PATH"
export HADOOP_CONF_DIR="$HADOOP_HOME/etc/hadoop"
export CLASSPATH="$JAVA_HOME/lib:$SPARK_HOME/jars:$SCALA_HOME/lib:$(hadoop classpath)"
export LD_LIBRARY_PATH="$HADOOP_HOME/lib/native:$LD_LIBRARY_PATH"
export SPARK_LOCAL_IP="127.0.0.1"

cd $PWD0
